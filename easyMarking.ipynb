{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b62878",
   "metadata": {},
   "source": [
    "# An easy *mitoSpotter* running pipeline for markers <img src='./webui/static/logo.png' align=\"right\" alt=\"\" width=\"120\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd7822",
   "metadata": {},
   "source": [
    "All the data, scripts, and output from scripts are already in-place in our well-structured directory. Detailed file connection illustration is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b76c69",
   "metadata": {},
   "source": [
    "![All scripts documentation](./webui/static/All_scripts_documentation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae90f8c",
   "metadata": {},
   "source": [
    "All the preprocessed dataset (e.g., output from 01-03 scripts have been deposited in out_dir directory, but if you want to run this part, you can still do it!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9eaded",
   "metadata": {},
   "source": [
    "## At a glimpse: Overall script structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cb819",
   "metadata": {},
   "source": [
    "/mitoSpotter/scripts  \n",
    "├── 01_from_gtf_extract_id.py  \n",
    "├── 02_fasta_split_by_id.py  \n",
    "├── 03_sequence2unit_nt.py  \n",
    "├── 04_train_hmm_nt.py  \n",
    "└── 05_decode_path_nt.py  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e54b5a",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "\n",
    "- Make sure you have configure the environment correctly (described in Documentation), and selected the right kernel for this run.\n",
    "- Download [human cds genome file](https://42basepairs.com/browse/web/ensembl/release-82/fasta/homo_sapiens/cds?file=Homo_sapiens.GRCh38.cds.all.fa.gz&preview=) and [GTF file](https://ftp.ensembl.org/pub/release-115/gtf/homo_sapiens/Homo_sapiens.GRCh38.115.chr.gtf.gz) into '/mitoSpotter/data' folder (this step might take a while).\n",
    "- Import the package below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import runpy\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9b62d",
   "metadata": {},
   "source": [
    "## STEP 1: EXTRACT NUCLEAR AND MITOCHONDRIA GENE ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    \"scripts/01_from_gtf_extract_id.py\",\n",
    "    \"--gtf\", \"data/Homo_sapiens.GRCh38.115.chr.gtf\",\n",
    "    \"--outdir\", \"out_dir/01_ids\",\n",
    "    \"--prefix\", \"human_protein_coding_marker_testing_\",\n",
    "    \"--protein_coding_only\",\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/01_from_gtf_extract_id.py\", run_name=\"__main__\")\n",
    "\n",
    "# This equals to running \n",
    "\n",
    "# python scripts/01_from_gtf_extract_id.py \\\n",
    "#   --gtf data/Homo_sapiens.GRCh38.115.chr.gtf \\\n",
    "#   --outdir out_dir/01_ids \\\n",
    "#   --protein_coding_only \\\n",
    "#   --prefix human_protein_coding_\n",
    "\n",
    "# at the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac07075",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "\n",
    "![01 output](./webui/static/01_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b87929",
   "metadata": {},
   "source": [
    "## 02 SPLIT FASTA BY ID\n",
    "\n",
    "In this step, we want to get the sequence with these ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    \"scripts/02_fasta_split_by_id.py\",\n",
    "    \"--fasta\", \"data/Homo_sapiens.GRCh38.cds.all.fa\",\n",
    "    \"--mito_ids\", \"out_dir/01_ids/human_protein_coding_marker_testing_ids_mito.txt\",\n",
    "    \"--nuc_ids\", \"out_dir/01_ids/human_protein_coding_marker_testing_ids_nuclear.txt\",\n",
    "    \"--outdir\", \"out_dir/02_split_fasta\",\n",
    "    \"--prefix\", \"human_marker_testing_\",\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/02_fasta_split_by_id.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff831b4",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "\n",
    "![02 output](./webui/static/02_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5342bc",
   "metadata": {},
   "source": [
    "## 03 TOKENIZATION AND SPLIT INTO TRAINING AND HOLDOUT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter combinations\n",
    "locations = [\"nuclear\", \"mito\"]\n",
    "kinds = [\"cds\"]\n",
    "modes = [\"3nt\", \"2nt\", \"1nt\"]\n",
    "\n",
    "# Iterate through all combinations\n",
    "for loc, kind, mode in itertools.product(locations, kinds, modes):\n",
    "    sys.argv = [\n",
    "        \"scripts/03_sequence2unit_nt.py\",\n",
    "        \"--fasta\", f\"out_dir/02_split_fasta/human_{loc}_{kind}.fa\",\n",
    "        \"--mode\", mode,\n",
    "        \"--train_tsv\", f\"out_dir/03_unit/train/human_marker_testing_{loc}_{mode}_train.tsv\",\n",
    "        \"--holdout_tsv\", f\"out_dir/03_unit/holdout/human_marker_testing_{loc}_{mode}_holdout.tsv\",\n",
    "        \"--train_frac\", \"0.7\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running: {loc} {kind} {mode}\")\n",
    "    runpy.run_path(\"scripts/03_sequence2unit_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033a341",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "\n",
    "![03 output](./webui/static/03_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b5e5f6",
   "metadata": {},
   "source": [
    "## 04 HMM TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f523c6",
   "metadata": {},
   "source": [
    "Yeahh! Finally comes into training phase! Let me take 3-nt level for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf101d7",
   "metadata": {},
   "source": [
    "![04 param](./webui/static/04_param.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9f4de",
   "metadata": {},
   "source": [
    "### EM run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c05be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    \"scripts/04_train_hmm_nt.py\",\n",
    "    \"--nuclear_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_nuclear_3nt_train.tsv\",\n",
    "    \"--mito_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_mito_3nt_train.tsv\",\n",
    "    \"--ngram\", \"3\",\n",
    "    \"--train_method\", \"em\",\n",
    "    \"--learn\", \"et\", # use et to learn both emission and transition, essential!\n",
    "    \"--n_em_iter\", \"20\",\n",
    "    \"--out_model_json\", \"out_dir/04_model/human_marker_testing_3nt_model_em.json\",\n",
    "    \"--out_vocab_json\", \"out_dir/04_model/human_marker_testing_3nt_vocab_em.json\",\n",
    "    \"--out_states_json\", \"out_dir/04_model/human_marker_testing_3nt_states_em.json\",\n",
    "    \"--sample\", \"0.0001\", # downsample for faster training, expected to take less than 1 minute\n",
    "    \"--track_memory\",\n",
    "    \"--n_workers\", \"2\", # if you use mac or linux, add this, otherwise remove this line\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/04_train_hmm_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c8d19",
   "metadata": {},
   "source": [
    "### Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    \"scripts/04_train_hmm_nt.py\",\n",
    "    \"--nuclear_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_nuclear_3nt_train.tsv\",\n",
    "    \"--mito_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_mito_3nt_train.tsv\",\n",
    "    \"--ngram\", \"3\",\n",
    "    \"--train_method\", \"viterbi\",\n",
    "    \"--n_viterbi_iter\", \"20\",\n",
    "    \"--out_model_json\", \"out_dir/04_model/human_marker_testing_3nt_model_viterbi.json\",\n",
    "    \"--out_vocab_json\", \"out_dir/04_model/human_marker_testing_3nt_vocab_viterbi.json\",\n",
    "    \"--out_states_json\", \"out_dir/04_model/human_marker_testing_3nt_states_viterbi.json\",\n",
    "    \"--sample\", \"0.0001\", # downsample for faster training, expected to take less than 1 minute\n",
    "    \"--track_memory\",\n",
    "    \"--n_workers\", \"2\", # if you use mac or linux, add this, otherwise remove this line\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/04_train_hmm_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc08a0",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebe8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make em 0.5 and viterbi 0.5 (1:1)\n",
    "\n",
    "sys.argv = [\n",
    "    \"scripts/04_train_hmm_nt.py\",\n",
    "    \"--nuclear_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_nuclear_3nt_train.tsv\",\n",
    "    \"--mito_nt_tsv\", \"out_dir/03_unit/train/human_marker_testing_mito_3nt_train.tsv\",\n",
    "    \"--ngram\", \"3\",\n",
    "    \"--train_method\", \"hybrid\",\n",
    "    \"--n_em_iter\", \"10\",\n",
    "    \"--n_viterbi_iter\", \"10\",\n",
    "    \"--learn\", \"et\", # use et to learn both emission and transition, essential!\n",
    "    \"--out_model_json\", \"out_dir/04_model/human_marker_testing_3nt_model_hybird.json\",\n",
    "    \"--out_vocab_json\", \"out_dir/04_model/human_marker_testing_3nt_vocab_hybird.json\",\n",
    "    \"--out_states_json\", \"out_dir/04_model/human_marker_testing_3nt_states_hybird.json\",\n",
    "    \"--sample\", \"0.0001\", # downsample for faster training, expected to take less than 1 minute\n",
    "    \"--track_memory\",\n",
    "    \"--n_workers\", \"2\", # if you use mac or linux, add this, otherwise remove this line\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/04_train_hmm_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6add60c",
   "metadata": {},
   "source": [
    "## 05 SEQUENCE DECODING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72af74",
   "metadata": {},
   "source": [
    "![05 param](./webui/static/05_param.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def14e14",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78260898",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "  \"05_decode_path_nt.py\",\n",
    "\n",
    "  # Load the model!\n",
    "  \"--model_json\", \"out_dir/04_model/human_marker_testing_3nt_model_em.json\",\n",
    "  \"--vocab_json\", \"out_dir/04_model/human_marker_testing_3nt_vocab_em.json\",\n",
    "  \"--states_json\", \"out_dir/04_model/human_marker_testing_3nt_states_em.json\",\n",
    "\n",
    "  # correspondingly, use the \"3-nt\" mode\n",
    "  \"--ngram\", \"3\",\n",
    "\n",
    "  # An example file of fasta sequences (from a becteria which has a relatively small phylogenetic distance to mitochondria genes)\n",
    "  \"--fasta\", \"./webui/static/Rickettsia_prowazekii_str_Madrid_E.fa\",\n",
    "\n",
    "  # don't decode too short sequences (<10)\n",
    "  \"--min_len\", \"10\",\n",
    "\n",
    "  # Write output\n",
    "  \"--out_tsv\", \"out_dir/05_res/human_marker_testing_fasta_res.tsv\",\n",
    "\n",
    "  \"--plotting\", # plot the results! the plots will be saved in the same directory where you run the script\n",
    "  \"--track_memory\",\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/05_decode_path_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a2beb",
   "metadata": {},
   "source": [
    "### STDIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907e100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f35f22",
   "metadata": {},
   "source": [
    "### ARGUMENT SEQUENCE PASSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929aa50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "  \"05_decode_path_nt.py\",\n",
    "\n",
    "  # Load the model!\n",
    "  \"--model_json\", \"out_dir/04_model/human_marker_testing_3nt_model_em.json\",\n",
    "  \"--vocab_json\", \"out_dir/04_model/human_marker_testing_3nt_vocab_em.json\",\n",
    "  \"--states_json\", \"out_dir/04_model/human_marker_testing_3nt_states_em.json\",\n",
    "\n",
    "  # correspondingly, use the \"3-nt\" mode\n",
    "  \"--ngram\", \"3\",\n",
    "\n",
    "  # don't decode too short sequences (<10)\n",
    "  \"--min_len\", \"10\",\n",
    "\n",
    "  # The first sequence\n",
    "  \"--seq\", \"ATACCCATGGCCAACCTCCTACTCCTCATTGTACCCATTCTAATCGCAATGGCATTCCTAATGCTTACCGAACGAAAAATTCTAGGCTATATACAACTACGCAAAGGCCCCAACGTTGTAGGCCCCTACGGGCTACTACAACCCTTCGCTGACGCCATAAAACTCTTCACCAAAGAGCCCCTAAAACCCGCCACATCTACCATCACCCTCTACATCACCGCCCCGACCTTAGCTCTCACCATCGCTCTTCTACTATGAACCCCCCTCCCCATACCCAACCCCCTGGTCAACCTCAACCTAGGCCTCCTATTTATTCTAGCCACCTCTAGCCTAGCCGTTTACTCAATCCTCTGATCAGGGTGAGCATCAAACTCAAACTACGCCCTGATCGGCGCACTGCGAGCAGTAGCCCAAACAATCTCATATGAAGTCA\",\n",
    "  \"--seq_id\", \"marker_test_1\",\n",
    "\n",
    "  # The second sequence\n",
    "  \"--seq\",\n",
    "  \"GTCACCCTAGCCATCATTCTACTATCAACATTACTAATAAGTGGCTCCTTTAACCTCTCCACCCTTATCACAACACAAGAACACCTCTGATTACTCCTGCCATCATGACCCTTGGCCATAATATGATTTATCTCCACACTAGCAGAGACCAACCGAACCCCCTTCGACCTTGCCGAAGGGGAGTCCGAACTAGTCTCAGGCTTCAACATCGAATACGCCGCAGGCCCCTTCGCCCTATTCTTCATAGCCGAATACACAAACATTATTATAATAAACACCCTCACCACTACAATCTTCCTAGGAACAACATATGACGCACTCTCCCCTGAACTCTACACAACATATTTTGTCACCAAGACCCTACTTCTAACCTCCCTGTTCTTATGAATTCGAACAGCATACCCCCGATTCCGCTACGACCAACTCATACACCTCCTATGAAAAAACTTCCTACCACTCACCCTAGCATTACTTATATGATATGTCTCCATACCCATTACAATCTCCAGCATTCCCCCTCAAACC\",\n",
    "  \"--seq_id\", \"marker_test_2\",\n",
    "\n",
    "  # Write output\n",
    "  \"--out_tsv\", \"out_dir/05_res/human_marker_testing_arg_res.tsv\",\n",
    "\n",
    "  \"--plotting\", # plot the results! the plots will be saved in the same directory where you run the script\n",
    "  \"--track_memory\",\n",
    "]\n",
    "\n",
    "runpy.run_path(\"scripts/05_decode_path_nt.py\", run_name=\"__main__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525d12d",
   "metadata": {},
   "source": [
    "A glimpse of figures:\n",
    "\n",
    "How many seuquences in a batch are classified as nuclear and how many are mitochondria:\n",
    "\n",
    "![classification_counts](./webui/static/Plot_example/classification_counts.png)\n",
    "\n",
    "GC content in each gene sequence:\n",
    "\n",
    "![gc_content_stacked_bar](./webui/static/Plot_example/gc_content_stacked_bar.png)\n",
    "\n",
    "Log likelihood distribution of each sequence:\n",
    "\n",
    "![loglikelihood_distribution](./webui/static/Plot_example/loglikelihood_distribution.png)\n",
    "\n",
    "Hidden staten proportion in each gene sequence:\n",
    "\n",
    "![state_proportions_stacked_bar](./webui/static/Plot_example/state_proportions_stacked_bar.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
